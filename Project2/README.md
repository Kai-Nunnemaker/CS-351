|Thread<br>Count|Wall Clock<br>Time|User Time|System Time|Speedup|
|:--:|--:|--:|--:|:--:|
|1|14.47|13.85| 0.51|1.00|
|2| 7.66|14.22| 0.53| 1.89|
|3| 5.78|15.47| 0.78| 2.50|
|4| 4.75|16.65| 0.80| 3.05|
|5| 3.94|16.55| 0.96| 3.67|
|6| 3.47|16.83| 1.06| 4.17|
|7| 3.07|16.83| 1.19| 4.71|
|8| 2.79|16.81| 1.33| 5.19|
|16| 2.02|17.95| 3.01| 7.16|
|24| 1.94|18.80| 6.71| 7.46|
|32| 1.92|18.16|13.83| 7.54|
|40| 1.95|17.66|16.99| 7.42|
|48| 1.93|17.15|26.98| 7.50|
|56| 1.96|16.91|27.07| 7.38|
|64| 1.93|17.26|28.66| 7.50|
|72| 1.91|16.98|28.93| 7.58|
|80| 1.96|17.46|25.60| 7.38|

![speedup_plot](https://github.com/user-attachments/assets/1555e821-43d5-4fc9-9ce4-134a332f5f2e)

## Amdahlâ€™sâ€‘Law Prediction for 16 Threads

**Timings (1 thread):**
main program 0.007619994â€¯s
results outputâ€¯0.108451951â€¯s
total run timeâ€¯7.031054051â€¯s



Compute the serial fraction \(s\) and parallel fraction \(p\):


s = \frac{0.007619994 + 0.108451951}{7.031054051} = 0.016505 \quad(1.65\%)  
p = 1 - s = 0.983495
Plug into Amdahlâ€™s formula with 
ğ‘›
=
16
n=16:

$$
\mathrm{speedup}(16)
= \frac{1}{\,s + \dfrac{p}{16}\,}
= \frac{1}{\,0.016505 + \dfrac{0.983495}{16}\,}
\approx 12.82
$$
Linear Trend & Curve Flattening
Earlyâ€‘thread slope (1 â†’ 7 threads):

ğ‘†
7
âˆ’
ğ‘†
1
7
âˆ’
1
=
4.71
âˆ’
1.00
6
â‰ˆ
0.62
7âˆ’1
S 
7
â€‹
 âˆ’S 
1
â€‹
 
â€‹
 = 
6
4.71âˆ’1.00
â€‹
 â‰ˆ0.62
Lateâ€‘thread slope (32 â†’ 40 threads):

ğ‘†
40
âˆ’
ğ‘†
32
40
âˆ’
32
=
7.42
âˆ’
7.54
8
â‰ˆ
âˆ’
0.015
40âˆ’32
S 
40
â€‹
 âˆ’S 
32
â€‹
 
â€‹
 = 
8
7.42âˆ’7.54
â€‹
 â‰ˆâˆ’0.015
Why it flattens:
Even with â‰ˆâ€¯98â€¯% of the work parallelizable, overhead from threadâ€‘creation and synchronization, cacheâ€‘coherency traffic, and limited memoryâ€‘bandwidth means that after ~32 cores adding more threads yields diminishingâ€”or even negativeâ€”returns. Itâ€™s just like too many people crowding a single turnstile: beyond a certain point extra folks only increase waiting time rather than throughput.


